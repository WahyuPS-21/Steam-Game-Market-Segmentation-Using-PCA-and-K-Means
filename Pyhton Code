# -*- coding: utf-8 -*-
"""Steam Game Market Segmentation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjjPxo-dEWvv7vTnYgt-Ojf6xne2n-qS

# Reading the Data
"""

import pandas as pd

df = pd.read_excel("Steam_2024_bestRevenue_1500 (1).xlsx")

df.head(10)

df.info()

import numpy as np
from sklearn.preprocessing import LabelEncoder

df.head(10)

label_encoder = LabelEncoder()
label_encoder_platform = label_encoder.fit(df['publisherClass'])

# Memisahkan kolom numerik dan non-numerik
num_cols = df.select_dtypes(include=np.number).columns
non_num_cols = df.select_dtypes(exclude=np.number).columns
non_num_cols = non_num_cols.drop(['releaseDate', 'publishers', 'developers', 'name'])
# Melakukan label encoding pada semua kolom non-numerik
label_encoder = LabelEncoder()
for col in non_num_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Tampilkan hasil
df.head(10)

print(label_encoder_platform.classes_)
# Membuat DataFrame mapping untuk kolom 'platform'
mapping_df = pd.DataFrame({'original': label_encoder_platform.classes_,
                           'encoded': range(len(label_encoder_platform.classes_))})
print(mapping_df)

"""Sebelum dan sesudah mengubah menjadi angka

# Correlation matrix
"""

# Menghitung matriks kovarian
correlation_matrix = df[['bulan rilis', 'copiesSold', 'price', 'revenue', 'avgPlaytime', 'reviewScore', 'publisherClass']].corr()

# Menampilkan matriks kovarian
correlation_matrix

# Menghitung nilai eigen dan vektor eigen dari matriks korelasi
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

# Membuat DataFrame untuk menampilkan nilai eigen dan vektor eigen dengan rapi
eigen_df = pd.DataFrame({'Eigenvalue': eigenvalues,
                         'Eigenvector': [eigenvectors[:, i] for i in range(len(eigenvalues))]})

# Menampilkan DataFrame dengan format yang rapi
print(eigen_df.to_string(index=False))

"""# Check Normality"""

# Check for duplicate rows
duplicate = df[df.duplicated()]

print('Jumlah data duplikat =', len(duplicate))

# Display the duplicate rows (if any)
if not duplicate.empty:
  print("\nDuplicate Rows:")
  print(duplicate)

df.isnull().sum()

import matplotlib.pyplot as plt

# Pilih kolom tertentu
selected_cols = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Buat subplots yang sesuai dengan jumlah kolom yang dipilih
num_cols = len(selected_cols)
rows = (num_cols // 3) + (num_cols % 3 > 0)  # Mengatur jumlah baris secara dinamis
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))

fig.suptitle('Box Plots Outlier', fontsize=16)

# Flatten axes jika hanya satu baris
axes = axes.flatten() if num_cols > 1 else [axes]

# Plot setiap kolom yang dipilih
for i, col in enumerate(selected_cols):
    df.boxplot(column=col, ax=axes[i])
    axes[i].set_title(f'{col}')

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# StandardScaler Handling"""

df_standarscaler=df.copy()

df_standarscaler.head(10)

from sklearn.preprocessing import StandardScaler

# Pilih kolom yang akan di-handle outliernya
cols_to_scale = ["copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Buat objek StandardScaler
scaler = StandardScaler()

# Lakukan scaling pada kolom yang dipilih
df_standarscaler[cols_to_scale] = scaler.fit_transform(df_standarscaler[cols_to_scale])

# Tampilkan hasil
df_standarscaler.head(10)

# Pilih kolom yang akan diplot
cols_to_plot = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Membuat subplots yang sesuai dengan jumlah kolom yang dipilih
num_cols = len(cols_to_plot)
rows = (num_cols // 3) + (num_cols % 3 > 0)  # Mengatur jumlah baris secara dinamis
fig, axes = plt.subplots(nrows=rows, ncols=3, figsize=(15, 10))

fig.suptitle('Box Plots Outlier (df_standarscaler)', fontsize=16)

# Flatten axes jika hanya satu baris
axes = axes.flatten() if num_cols > 1 else [axes]

# Plot setiap kolom yang dipilih
for i, col in enumerate(cols_to_plot):
    df_standarscaler.boxplot(column=col, ax=axes[i])
    axes[i].set_title(f'{col}')

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# Winsorizing Handling"""

df_winsorizing=df.copy()

df_winsorizing.head(10)

from scipy.stats.mstats import winsorize

# Pilih kolom yang akan di-winsorize
cols_to_winsorize = ["copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Lakukan winsorizing pada setiap kolom yang dipilih
for col in cols_to_winsorize:
  df_winsorizing[col] = winsorize(df_winsorizing[col], limits=[0.05, 0.05])  # Mengubah 5% data terkecil dan terbesar

# Tampilkan hasil
df_winsorizing.head(10)

import matplotlib.pyplot as plt
# Pilih kolom yang akan diplot
cols_to_plot = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Membuat subplots yang sesuai dengan jumlah kolom yang dipilih
num_cols = len(cols_to_plot)
rows = (num_cols // 3) + (num_cols % 3 > 0)  # Mengatur jumlah baris secara dinamis
fig, axes = plt.subplots(nrows=rows, ncols=3, figsize=(15, 10))

fig.suptitle('Box Plots Outlier (df_winsorizing)', fontsize=16)

# Flatten axes jika hanya satu baris
axes = axes.flatten() if num_cols > 1 else [axes]

# Plot setiap kolom yang dipilih
for i, col in enumerate(cols_to_plot):
    df_winsorizing.boxplot(column=col, ax=axes[i])
    axes[i].set_title(f'{col}')

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# RobustScaler Handling"""

df_robustscaler=df.copy()

df_robustscaler.head(10)

from sklearn.preprocessing import RobustScaler

# Pilih kolom yang akan di-handle outliernya
cols_to_scale = ["copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Buat objek RobustScaler
scaler = RobustScaler()

# Lakukan scaling pada kolom yang dipilih
df_robustscaler[cols_to_scale] = scaler.fit_transform(df_robustscaler[cols_to_scale])

# Tampilkan hasil
df_robustscaler.head(10)

import matplotlib.pyplot as plt
# Pilih kolom yang akan diplot
cols_to_plot = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Membuat subplots yang sesuai dengan jumlah kolom yang dipilih
num_cols = len(cols_to_plot)
rows = (num_cols // 3) + (num_cols % 3 > 0)  # Mengatur jumlah baris secara dinamis
fig, axes = plt.subplots(nrows=rows, ncols=3, figsize=(15, 10))

fig.suptitle('Box Plots Outlier RobustScaler ', fontsize=16)

# Flatten axes jika hanya satu baris
axes = axes.flatten() if num_cols > 1 else [axes]

# Plot setiap kolom yang dipilih
for i, col in enumerate(cols_to_plot):
    df_robustscaler.boxplot(column=col, ax=axes[i])
    axes[i].set_title(f'{col}')

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# IQR Handling"""

df_iqr=df.copy()

df_iqr.head(10)

def handle_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - (1.5 * IQR)
    upper_bound = Q3 + (1.5 * IQR)

    # Ganti outlier dengan batas atas atau batas bawah
    df[column] = df[column].apply(lambda x: upper_bound if x > upper_bound else lower_bound if x < lower_bound else x)

    return df

# Kolom-kolom yang akan ditangani outlier-nya
kolom_outlier = ["copiesSold", "revenue", "avgPlaytime"]

# Loop melalui setiap kolom dan tangani outlier
for kolom in kolom_outlier:
    df_iqr = handle_outliers_iqr(df_iqr, kolom)

# Tampilkan beberapa baris pertama dari DataFrame yang sudah ditangani outlier-nya
df_iqr.head(10)

import matplotlib.pyplot as plt
# Pilih kolom yang akan diplot
cols_to_plot = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore"]

# Membuat subplots yang sesuai dengan jumlah kolom yang dipilih
num_cols = len(cols_to_plot)
rows = (num_cols // 3) + (num_cols % 3 > 0)  # Mengatur jumlah baris secara dinamis
fig, axes = plt.subplots(nrows=rows, ncols=3, figsize=(15, 10))

fig.suptitle('Plot Outlier Interquartile Range ', fontsize=16)

# Flatten axes jika hanya satu baris
axes = axes.flatten() if num_cols > 1 else [axes]

# Plot setiap kolom yang dipilih
for i, col in enumerate(cols_to_plot):
    df_iqr.boxplot(column=col, ax=axes[i])
    axes[i].set_title(f'{col}')

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# Max-min Handling"""

df_maxmin = df.copy()

df_maxmin.head(10)

# Buat objek scaler
scaler = MinMaxScaler()

# Lakukan scaling dan buat kolom baru
# Nama kolom baru akan sama dengan aslinya ditambah akhiran '_maxmin'
scaled_cols = [col + '_maxmin' for col in cols_to_scale]
df_maxmin[scaled_cols] = scaler.fit_transform(df_maxmin[cols_to_scale])

df_maxmin.head()

# Pilih kolom yang akan diplot (pastikan ini kolom yang sama yang Anda normalisasi)
cols_to_plot = ["bulan rilis", "copiesSold_maxmin", "price_maxmin", "revenue_maxmin", "avgPlaytime_maxmin", "reviewScore_maxmin"]

# Membuat subplots yang sesuai dengan jumlah kolom yang dipilih
num_cols = len(cols_to_plot)
rows = (num_cols // 3) + (num_cols % 3 > 0)  # Mengatur jumlah baris secara dinamis
fig, axes = plt.subplots(nrows=rows, ncols=3, figsize=(15, 10))

fig.suptitle('Box Plots Outlier Max-Min Normalization', fontsize=16)

# Flatten axes jika hanya satu baris
axes = axes.flatten() if num_cols > 1 else [axes]

# Plot setiap kolom yang dipilih
for i, col in enumerate(cols_to_plot):
    df_maxmin.boxplot(column=col, ax=axes[i])
    axes[i].set_title(f'{col}')

# Hapus subplot kosong jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""# PCA

"""

df_pca1 = df_standarscaler.copy()
df_pca1

df_pca2 = df_winsorizing.copy()
df_pca2

df_pca3 = df_robustscaler.copy()
df_pca3

df_pca4 = df_iqr.copy()
df_pca4

df_pca5 = df_maxmin.copy()
df_pca5

"""Perkalian Matriks"""

import numpy as np
# Menghitung nilai eigen dan vektor eigen dari matriks korelasi
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

# Menampilkan nilai eigen dan vektor eigen
print("Nilai Eigen:")
print(eigenvalues)
print("\nVektor Eigen:")
eigenvectors

print(eigen_df.to_string(index=False))

# Urutkan nilai eigen dari terbesar ke terkecil
sorted_eigenvalues = np.sort(eigenvalues)[::-1]

# Hitung proporsi variansi
total_eigenvalues = np.sum(sorted_eigenvalues)
proportions = []
cumulative_proportion = 0
for eigenvalue in sorted_eigenvalues:
  proportion = (eigenvalue / total_eigenvalues) * 100
  cumulative_proportion += proportion
  proportions.append(cumulative_proportion)

# Cetak proporsi variansi
for i, proportion in enumerate(proportions):
  print(f"Proporsi Variansi hingga Eigenvalue {i+1}: {proportion}%")

"""Standar Scaler"""

# 1. Daftar nilai eigen yang kamu pilih
target_eigenvalues = [1.81763, 1.263059, 1.101308, 0.957739, 0.906208, 0.592311]

# 2. Hitung nilai dan vektor eigen dari correlation matrix
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

# 3. Cari indeks dari nilai eigen yang mendekati target
selected_indices = []
for val in target_eigenvalues:
    idx = np.argmin(np.abs(eigenvalues - val))
    selected_indices.append(idx)

# 4. Ambil eigenvektor yang sesuai (kolom pada eigenvectors)
selected_eigenvectors = eigenvectors[:, selected_indices]  # shape: 7 x 6

# 5. Ambil 7 kolom data
cols_to_multiply = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore", "publisherClass"]
matrix_to_multiply = df_pca1[cols_to_multiply].values  # shape: n x 7

# 6. Lakukan kombinasi linier data dengan eigenvektor terpilih
result_matrix = np.dot(matrix_to_multiply, selected_eigenvectors)  # shape: n x 6

# 7. Buat DataFrame dari hasil
df_pca1_multiplied = pd.DataFrame(result_matrix, columns=[f"kolom_{i+1}" for i in range(len(selected_indices))])

# 8. Tampilkan hasil
df_pca1_multiplied

"""winsorizing"""

# 1. Daftar nilai eigen yang kamu pilih
target_eigenvalues = [1.81763, 1.263059, 1.101308, 0.957739, 0.906208, 0.592311]

# 2. Hitung nilai dan vektor eigen dari correlation matrix
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

# 3. Cari indeks dari nilai eigen yang mendekati target
selected_indices = []
for val in target_eigenvalues:
    idx = np.argmin(np.abs(eigenvalues - val))
    selected_indices.append(idx)

# 4. Ambil eigenvektor yang sesuai (kolom pada eigenvectors)
selected_eigenvectors = eigenvectors[:, selected_indices]  # shape: 7 x 6

# 5. Ambil 7 kolom data
cols_to_multiply = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore", "publisherClass"]
matrix_to_multiply = df_pca2[cols_to_multiply].values  # shape: n x 7

# 6. Lakukan kombinasi linier data dengan eigenvektor terpilih
result_matrix = np.dot(matrix_to_multiply, selected_eigenvectors)  # shape: n x 6

# 7. Buat DataFrame dari hasil
df_pca2_multiplied = pd.DataFrame(result_matrix, columns=[f"kolom_{i+1}" for i in range(len(selected_indices))])

# 8. Tampilkan hasil
df_pca2_multiplied

"""RobustScaler"""

# 1. Daftar nilai eigen yang kamu pilih
target_eigenvalues = [1.81763, 1.263059, 1.101308, 0.957739, 0.906208, 0.592311]

# 2. Hitung nilai dan vektor eigen dari correlation matrix
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

# 3. Cari indeks dari nilai eigen yang mendekati target
selected_indices = []
for val in target_eigenvalues:
    idx = np.argmin(np.abs(eigenvalues - val))
    selected_indices.append(idx)

# 4. Ambil eigenvektor yang sesuai (kolom pada eigenvectors)
selected_eigenvectors = eigenvectors[:, selected_indices]  # shape: 7 x 6

# 5. Ambil 7 kolom data
cols_to_multiply = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore", "publisherClass"]
matrix_to_multiply = df_pca3[cols_to_multiply].values  # shape: n x 7

# 6. Lakukan kombinasi linier data dengan eigenvektor terpilih
result_matrix = np.dot(matrix_to_multiply, selected_eigenvectors)  # shape: n x 6

# 7. Buat DataFrame dari hasil
df_pca3_multiplied = pd.DataFrame(result_matrix, columns=[f"kolom_{i+1}" for i in range(len(selected_indices))])

# 8. Tampilkan hasil
df_pca3_multiplied

"""IQR"""

# 1. Daftar nilai eigen yang kamu pilih
target_eigenvalues = [1.81763, 1.263059, 1.101308, 0.957739, 0.906208, 0.592311]

# 2. Hitung nilai dan vektor eigen dari correlation matrix
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)

# 3. Cari indeks dari nilai eigen yang mendekati target
selected_indices = []
for val in target_eigenvalues:
    idx = np.argmin(np.abs(eigenvalues - val))
    selected_indices.append(idx)

# 4. Ambil eigenvektor yang sesuai (kolom pada eigenvectors)
selected_eigenvectors = eigenvectors[:, selected_indices]  # shape: 7 x 6

# 5. Ambil 7 kolom data
cols_to_multiply = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore", "publisherClass"]
matrix_to_multiply = df_pca4[cols_to_multiply].values  # shape: n x 7

# 6. Lakukan kombinasi linier data dengan eigenvektor terpilih
result_matrix = np.dot(matrix_to_multiply, selected_eigenvectors)  # shape: n x 6

# 7. Buat DataFrame dari hasil
df_pca4_multiplied = pd.DataFrame(result_matrix, columns=[f"kolom_{i+1}" for i in range(len(selected_indices))])

# 8. Tampilkan hasil
df_pca4_multiplied

"""Max-Min"""

# 1. Daftar nilai eigen yang kamu pilih
target_eigenvalues = [1.81763, 1.263059, 1.101308, 0.957739, 0.906208, 0.592311]

# 2. Hitung nilai dan vektor eigen dari correlation matrix
eigenvalues, eigenvectors = np.linalg.eig(correlation_matrix)
# 3. Cari indeks dari nilai eigen yang mendekati target
selected_indices = []
for val in target_eigenvalues:
    idx = np.argmin(np.abs(eigenvalues - val))
    selected_indices.append(idx)

# 4. Ambil eigenvektor yang sesuai (kolom pada eigenvectors)
selected_eigenvectors = eigenvectors[:, selected_indices]  # shape: 7 x 6

# 5. Ambil 7 kolom data
cols_to_multiply = ["bulan rilis", "copiesSold", "price", "revenue", "avgPlaytime", "reviewScore", "publisherClass"]
matrix_to_multiply = df_pca5[cols_to_multiply].values  # shape: n x 7

# 6. Lakukan kombinasi linier data dengan eigenvektor terpilih
result_matrix = np.dot(matrix_to_multiply, selected_eigenvectors)  # shape: n x 6

# 7. Buat DataFrame dari hasil
df_pca5_multiplied = pd.DataFrame(result_matrix, columns=[f"kolom_{i+1}" for i in range(len(selected_indices))])

# 8. Tampilkan hasil
df_pca5_multiplied

"""# K-means Clustering

# Cluster 3

## Standar Scaler Cluster 3
"""

df_kmeans_pca1=df_pca1_multiplied.copy()
df_kmeans_pca1.head(10)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Inisialisasi model KMeans dengan 3 kluster
kmeans = KMeans(n_clusters=3, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans_pca1)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans_pca1['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans_pca1['kolom_1'], df_kmeans_pca1['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (3 Kluster)')
plt.legend()
plt.show()

# Menampilkan dataframe dengan kolom hasil kluster
df_kmeans_pca1

# prompt: lakukan evaluasi shiloutte coefficient pada  df_kmeans_minmax

from sklearn.metrics import silhouette_score

# Calculate Silhouette Coefficient
silhouette_avg_pca1 = silhouette_score(df_kmeans_pca1.drop('cluster', axis=1), df_kmeans_pca1['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_pca1}")

print(df_kmeans_pca1['cluster'].value_counts())

"""## Winsorizing cluster 3"""

df_kmeans_pca2=df_pca2_multiplied.copy()
df_kmeans_pca2.head(10)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Inisialisasi model KMeans dengan 3 kluster
kmeans = KMeans(n_clusters=3, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans_pca2)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans_pca2['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans_pca2['kolom_1'], df_kmeans_pca2['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (3 Kluster)')
plt.legend()
plt.show()

df_kmeans_pca2

# prompt: lakukan evaluasi shiloutte coefficient pada  df_kmeans_minmax

from sklearn.metrics import silhouette_score

# Calculate Silhouette Coefficient
silhouette_avg_pca2 = silhouette_score(df_kmeans_pca2.drop('cluster', axis=1), df_kmeans_pca2['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_pca2}")

print(df_kmeans_pca2['cluster'].value_counts())

"""## RobustScaler Cluster 3"""

df_kmeans_pca3=df_pca3_multiplied.copy()
df_kmeans_pca3.head(10)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Inisialisasi model KMeans dengan 3 kluster
kmeans = KMeans(n_clusters=3, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans_pca3)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans_pca3['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans_pca3['kolom_1'], df_kmeans_pca3['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (3 Kluster)')
plt.legend()
plt.show()

# prompt: lakukan evaluasi shiloutte coefficient pada  df_kmeans_minmax

from sklearn.metrics import silhouette_score

# Calculate Silhouette Coefficient
silhouette_avg_pca3 = silhouette_score(df_kmeans_pca3.drop('cluster', axis=1), df_kmeans_pca3['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_pca3}")

print(df_kmeans_pca3['cluster'].value_counts())

"""## IQR Cluster 3"""

df_kmeans_pca4=df_pca4_multiplied.copy()
df_kmeans_pca4.head(10)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Inisialisasi model KMeans dengan 3 kluster
kmeans = KMeans(n_clusters=3, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans_pca4)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans_pca4['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans_pca4['kolom_1'], df_kmeans_pca4['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (3 Kluster)')
plt.legend()
plt.show()

from sklearn.metrics import silhouette_score

# Calculate Silhouette Coefficient
silhouette_avg_pca4 = silhouette_score(df_kmeans_pca4.drop('cluster', axis=1), df_kmeans_pca4['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_pca4}")

print(df_kmeans_pca4['cluster'].value_counts())

"""## Max-Min Cluster 3"""

df_kmeans_pca5=df_pca5_multiplied.copy()
df_kmeans_pca5.head(10)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Inisialisasi model KMeans dengan 3 kluster
kmeans = KMeans(n_clusters=3, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans_pca5)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans_pca5['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans_pca5['kolom_1'], df_kmeans_pca5['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (3 Kluster)')
plt.legend()
plt.show()

# prompt: lakukan evaluasi shiloutte coefficient pada  df_kmeans_minmax

from sklearn.metrics import silhouette_score

# Calculate Silhouette Coefficient
silhouette_avg_pca5 = silhouette_score(df_kmeans_pca5.drop('cluster', axis=1), df_kmeans_pca5['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_pca5}")

print(df_kmeans_pca5['cluster'].value_counts())

"""# The method that has the best "Silhouette Coefficient" is the Max-Min method, but the method that has the least outlier data is the "IQR" method, therefore the "IQR" method will be used.

# Cluster 4
"""

df_kmeans4 = df_pca4_multiplied.copy()
df_kmeans4.head(10)

# Inisialisasi model KMeans dengan 4 kluster
kmeans = KMeans(n_clusters=4, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans4)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans4['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans4['kolom_1'], df_kmeans4['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (4 Kluster)')
plt.legend()
plt.show()

df_kmeans4

# Calculate Silhouette Coefficient
silhouette_avg_kmeans4 = silhouette_score(df_kmeans4.drop('cluster', axis=1), df_kmeans4['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_kmeans4}")

from google.colab import files
df_hasil_kmeans4 = df.copy()
df_hasil_kmeans4['cluster'] = df_kmeans4['cluster']

# Download the file
df_hasil_kmeans4.to_excel("Hasil 4 Kluster.xlsx", index=False)
files.download("Hasil 4 Kluster.xlsx")

"""#Cluster 5

"""

df_kmeans5 = df_pca4_multiplied.copy()
df_kmeans5.head(10)

# Inisialisasi model KMeans dengan 4 kluster
kmeans = KMeans(n_clusters=5, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans5)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans5['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans5['kolom_1'], df_kmeans5['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (5 Kluster)')
plt.legend()
plt.show()

df_kmeans5

# Calculate Silhouette Coefficient
silhouette_avg_kmeans5 = silhouette_score(df_kmeans5.drop('cluster', axis=1), df_kmeans5['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_kmeans5}")

df_hasil_kmeans5 = df.copy()
df_hasil_kmeans5['cluster'] = df_kmeans5['cluster']

# Download the file
df_hasil_kmeans5.to_excel("Hasil 5 Kluster.xlsx", index=False)
files.download("Hasil 5 Kluster.xlsx")

"""# Cluster 6"""

df_kmeans6 = df_pca4_multiplied.copy()
df_kmeans6.head(10)

# Inisialisasi model KMeans dengan 4 kluster
kmeans = KMeans(n_clusters=6, random_state=0)

# Melakukan klustering pada dataframe 'df_minmax_multiplied'
kmeans.fit(df_kmeans6)

# Mendapatkan label kluster untuk setiap data point
labels = kmeans.labels_

# Menambahkan kolom 'cluster' ke dataframe
df_kmeans6['cluster'] = labels

# Plot hasil klustering (contoh menggunakan dua kolom pertama)
plt.scatter(df_kmeans6['kolom_1'], df_kmeans6['kolom_2'], c=labels, cmap='viridis')
plt.xlabel('kolom_1')
plt.ylabel('kolom_2')
plt.title('Hasil Klustering K-Means (5 Kluster)')
plt.legend()
plt.show()

df_kmeans6

# Calculate Silhouette Coefficient
silhouette_avg_kmeans6 = silhouette_score(df_kmeans6.drop('cluster', axis=1), df_kmeans6['cluster'])

print(f"Silhouette Coefficient: {silhouette_avg_kmeans6}")

df_hasil_kmeans6 = df.copy()
df_hasil_kmeans6['cluster'] = df_kmeans6['cluster']

# Download the file
df_hasil_kmeans6.to_excel("Hasil 6 Kluster.xlsx", index=False)
files.download("Hasil 6 Kluster.xlsx")

df_hasil_kmeans3 = df.copy()
df_hasil_kmeans3['cluster'] = df_kmeans_pca4['cluster']

# Download the file
df_hasil_kmeans3.to_excel("Hasil 3 Kluster.xlsx", index=False)
files.download("Hasil 3 Kluster.xlsx")
